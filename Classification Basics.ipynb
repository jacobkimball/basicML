{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "julian-halloween",
   "metadata": {},
   "source": [
    "## Simple Classification Example\n",
    "\n",
    "Let's start with loading all necessary packages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd               \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaningful-steel",
   "metadata": {},
   "source": [
    "For this classification example, we are going to work with the Wisconson breast cancer dataset, containing information on 30 features from 569 patients. Each example is labeled as 'malignant' or 'benign'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = load_breast_cancer() # import data\n",
    "\n",
    "X, y = cancer_data.data, cancer_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-transcription",
   "metadata": {},
   "source": [
    "***\n",
    "Notes: \n",
    "\n",
    "If you want to see which features have good separation between the classes, check out seaborn.kdeplot().  \n",
    "For each feature, plot the distributions of malignant and benign and see how much they overlap\n",
    "\n",
    "After the features have been extracted, the only big difference to look out for with biomed data \n",
    "is splitting by patient if each patient has more than one example. That isn't the case in this dataset. \n",
    "\n",
    "Remember that we also need to standardize this data for certain classifiers to perform well. \n",
    "Read up on the difference between standardization and normalization and when you would use which.  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-cholesterol",
   "metadata": {},
   "source": [
    "Now we need to split the data into a training set and test set, and standardize the features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1) # 80/20 split \n",
    "\n",
    "# standardization (subtract the mean and divide by the variance - or just use this function)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test) # we apply the same transformation to X_test that we did to X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-population",
   "metadata": {},
   "source": [
    "In this next step, we split the training set for 5-fold cross validation to test different hyperparameter values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up 5 folds \n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# create list of hyperparameter values to test out. Starting with a decade search \n",
    "hparams = np.array([0.0001, 0.001, 0.01, 0.1, 0.5, 1, 10])\n",
    "\n",
    "# create placeholders for error measures\n",
    "SVM_rbf_tn_error = np.zeros([len(hparams),1]) # training error for SVM with rbf kernel\n",
    "SVM_rbf_vl_error = np.zeros([len(hparams),1]) # validation error\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    xtn, xtt = X_train[train_index], X_train[test_index] # create mini training and testing sets\n",
    "    ytn, ytt = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    for j in range(0,len(hparams)): \n",
    "        SVM_rbf = svm.SVC( C=1, kernel='rbf', gamma=hparams[j]) # SVM with a radial basis function kernel\n",
    "        SVM_rbf.fit(xtn, ytn) # now you have a machine learning model\n",
    "        \n",
    "        y_pred_train = SVM_rbf.predict(xtn)\n",
    "        y_pred_test = SVM_rbf.predict(xtt)\n",
    "        \n",
    "        # compute simple accuracy metric \n",
    "        training_accuracy = np.sum(y_pred_train==ytn)/ytn.shape[0]\n",
    "        validation_accuracy = np.sum(y_pred_test==ytt)/ytt.shape[0]\n",
    "        \n",
    "        # update the error placeholders \n",
    "        SVM_rbf_tn_error[j,0] = SVM_rbf_tn_error[j,0]+(1-training_accuracy)\n",
    "        SVM_rbf_vl_error[j,0] = SVM_rbf_vl_error[j,0]+(1-validation_accuracy)\n",
    "        \n",
    "        \n",
    "# once out of the loop, you need to take the average of the error over the 5 folds \n",
    "SVM_rbf_tn_error = SVM_rbf_vl_error/5\n",
    "SVM_rbf_vl_error = SVM_rbf_vl_error/5\n",
    "\n",
    "fig = plt.figure(); \n",
    "plt.plot(hparams,SVM_rbf_tn_error,c = 'black',label='Training Error') \n",
    "plt.plot(hparams,SVM_rbf_vl_error,c = 'green',label='Validation Error')\n",
    "plt.xscale('log')\n",
    "plt.title('Training and Validation Error for SVM with rbf kernel')\n",
    "plt.xlabel('gamma',fontsize=12)\n",
    "plt.ylabel('Error',fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-affair",
   "metadata": {},
   "source": [
    "***\n",
    "It looks like a gamma of 0.1 is giving us the best validation error, so that's what we'll use to train the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_rbf = svm.SVC( C=1, kernel='rbf', gamma=0.1) # SVM with a radial basis function kernel\n",
    "SVM_rbf.fit(X_train, y_train) # now you have a machine learning model\n",
    "        \n",
    "y_pred_test = SVM_rbf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-watershed",
   "metadata": {},
   "source": [
    "Let's see how accurate this model is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred_test)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test,y_pred_test)\n",
    "precision = sklearn.metrics.precision_score(y_test,y_pred_test)\n",
    "recall = sklearn.metrics.recall_score(y_test,y_pred_test)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "print('Accuracy is: ' + str(accuracy*100) + '%')\n",
    "print('Precision is: ' + str(precision*100) + '%')\n",
    "print('Sensitivity is: ' + str(recall*100) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-asthma",
   "metadata": {},
   "source": [
    "***\n",
    "Now just for fun, we'll check what would have happened had we used a 'dummy' classifier, simply assuming that no patients had cancer. In this dataset, a prediction of 1 is a prediction that the sample is benign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check against the dummy classifier: assume all are non-cancer\n",
    "# in this dataset, a prediction of 1 is a prediction that the sample is benign\n",
    "\n",
    "y_pred_dummy = np.ones(y_test.shape)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test,y_pred_dummy)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test,y_pred_dummy)\n",
    "precision = sklearn.metrics.precision_score(y_test,y_pred_dummy)\n",
    "recall = sklearn.metrics.recall_score(y_test,y_pred_dummy)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "print('Accuracy is: ' + str(accuracy*100) + '%')\n",
    "print('Precision is: ' + str(precision*100) + '%')\n",
    "print('Sensitivity is: ' + str(recall*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-detection",
   "metadata": {},
   "source": [
    "***\n",
    "Although this was a pretty simple classification problem, I hope this helps you attack some more difficult problems in the future. \n",
    "\n",
    "Good luck! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-alias",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
